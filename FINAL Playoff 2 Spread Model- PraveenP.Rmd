---
title: "Playoffs 2 Data"
author: "Praveen Puviindran"
date: "2024-04-02"
output: pdf_document
---

```{r setup, include=FALSE}
library(readr)

nba_api <- read_csv("/Users/praveenpuviindran/Downloads/2019to2024nbagamestats.csv")

head(nba_api)
```

```{r}
# This script scrapes top-level NBA schedule and results from basketball-reference.com.
# User can set year and list of months to determine the window of games to scrape.
# At the end of the script, I reconstruct the conference standings based on W-L
# percentage.

library(rvest)
library(lubridate)
library(tidyverse)

########
# PARAMETERS
########
year <- "2024"
monthList <- c("october", "november", "december", "january", "february", 
               "march")
playoff_startDate <- ymd("2024-04-20")
outputfile <- "NBA-2024_game_data.rds"

########
# SCRIPT FOR SCRAPING DATA STARTS HERE
########
df <- data.frame()
for (month in monthList) {
  # get webpage
  url <- paste0("https://www.basketball-reference.com/leagues/NBA_", year, 
                "_games-", month, ".html")
  webpage <- read_html(url)
  
  # get column names
  col_names <- webpage %>% 
    html_nodes("table#schedule > thead > tr > th") %>% 
    html_attr("data-stat")    
  col_names <- c("game_id", col_names)
  
  # extract dates column
  # note that in april, there is a break in the table which just says 
  # "Playoffs". this messes with the data merging later, so we get rid of it
  dates <- webpage %>% 
    html_nodes("table#schedule > tbody > tr > th") %>% 
    html_text()
  dates <- dates[dates != "Playoffs"]
  
  # extract game id
  # we need to remove the NA that is due to the "Playoffs" row in april
  game_id <- webpage %>% 
    html_nodes("table#schedule > tbody > tr > th") %>%
    html_attr("csk")
  game_id <- game_id[!is.na(game_id)]
  
  # extract all columns (except date)
  data <- webpage %>% 
    html_nodes("table#schedule > tbody > tr > td") %>% 
    html_text() %>%
    matrix(ncol = length(col_names) - 2, byrow = TRUE)
  
  # combine game IDs, dates and columns in dataframe for this month, add col names
  month_df <- as.data.frame(cbind(game_id, dates, data), stringsAsFactors = FALSE)
  names(month_df) <- col_names
  
  # add to overall dataframe
  df <- rbind(df, month_df)
}

# change columns to the correct types
df$visitor_pts <- as.numeric(df$visitor_pts)
df$home_pts    <- as.numeric(df$home_pts)
df$attendance  <- as.numeric(gsub(",", "", df$attendance))
df$date_game   <- mdy(df$date_game)

# add column to indicate if regular season or playoff
df$game_type <- with(df, ifelse(date_game >= playoff_startDate, 
                                "Playoff", "Regular"))

# drop boxscore column
df$box_score_text <- NULL

# save to file
saveRDS(df, outputfile)

########
# SCRIPT FOR RANKING TABLE STARTS HERE
########

# get winner and loser of each game
df$winner <- with(df, ifelse(visitor_pts > home_pts, 
                             visitor_team_name, home_team_name))
df$loser <- with(df, ifelse(visitor_pts < home_pts, 
                            visitor_team_name, home_team_name))

# build up standings table for regular season
regular_df <- subset(df, game_type == "Regular")
regular_df <- na.omit(regular_df)
teams <- sort(unique(regular_df$visitor_team_name))
standings <- data.frame(team = teams, stringsAsFactors = FALSE)

# conference & division information: manually input
standings$conf <- c("East", "East", "East", "East", "East",
                    "East", "West", "West", "East", "West",
                    "West", "East", "West", "West", "West",
                    "East", "East", "West", "West", "East",
                    "West", "East", "East", "West", "West",
                    "West", "West", "East", "West", "East")
standings$div <- c("Southeast", "Atlantic", "Atlantic", "Southeast", "Central",
                   "Central", "Southwest", "Northwest", "Central", "Pacific",
                   "Southwest", "Central", "Pacific", "Pacific", "Southwest",
                   "Southeast", "Central", "Northwest", "Southwest", "Atlantic",
                   "Northwest", "Southeast", "Atlantic", "Pacific", "Northwest",
                   "Pacific", "Southwest", "Atlantic", "Northwest", "Southeast")

# populate W-L column, W pct
standings$win <- 0; standings$loss <- 0
for (i in 1:nrow(standings)) {
  standings$win[i]  <- sum(regular_df$winner == standings$team[i])
  standings$loss[i] <- sum(regular_df$loser  == standings$team[i])
}
standings$wl_pct <- with(standings, win / (win + loss))

# Eastern conference standings
east_standings <- subset(standings, conf == "East")
east_standings[with(east_standings, order(-wl_pct, team)), 
               c("team", "win", "loss")]

# Western conference standings
west_standings <- subset(standings, conf == "West")
west_standings[with(west_standings, order(-wl_pct, team)), 
               c("team", "win", "loss")]
```

```{r}
regular_df$home_prior_form <- nrow(regular_df)*NA

regular_df$visitor_prior_form <- nrow(regular_df)*NA



```

```{r}

for (i in 1:length(unique(regular_df$visitor_team_name))){
  

  adapted_df <- regular_df |> 
    filter(visitor_team_name == unique(regular_df$visitor_team_name)[i] | home_team_name == unique(regular_df$visitor_team_name)[i])
  

for (j in 1:(nrow(adapted_df) - 1)) 
  {

adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]


if(adapted_df$visitor_team_name[j] == unique(regular_df$visitor_team_name)[i]){
#Are selected team away?
  
      if(is.na(adapted_df$visitor_prior_form[j])){
        #Is var column empty?
          if(adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
            if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            
            adapted_df$visitor_prior_form[j+1] <- "W"
            }
            else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- "W"

            }
        }
        if(adapted_df$loser[j]  == unique(regular_df$visitor_team_name)[i]){
          #Did selected team lose?
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            
            adapted_df$visitor_prior_form[j+1] <- "L"
            }
            else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- "L"

            }
        }
      }
      else if(nchar(adapted_df$visitor_prior_form[j]) < 9){
        
        if(adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
          
          adapted_df$visitor_prior_form[j+1] <- paste(adapted_df$visitor_prior_form[j], "W")
       
          }
          else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$visitor_prior_form[j+1] <- paste(adapted_df$visitor_prior_form[j], "W")
          }
        }
        else if(adapted_df$loser[j] == unique(regular_df$visitor_team_name)[i]){
          #Team lost
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
          #Is team away next?
          adapted_df$visitor_prior_form[j+1] <- paste(adapted_df$visitor_prior_form[j], "L")
          
          }
          else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i])
            #Is team at home next?
            {
            adapted_df$home_prior_form[j+1] <- paste(adapted_df$visitor_prior_form[j], "L")
          }
        }
        }
        
 else if (nchar(adapted_df$visitor_prior_form[j]) >= 9){
        if (adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
          #Did team win?
          
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$visitor_prior_form[j+1] <- paste(substr(adapted_df$visitor_prior_form[j], 3, 9), "W")
          }
          
          if(adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(substr(adapted_df$visitor_prior_form[j], 3, 9), "W")
          }
          
            
            }
        else if (adapted_df$loser[j] == unique(regular_df$visitor_team_name)[i]){
          
          
           if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$visitor_prior_form[j+1] <- paste(substr(adapted_df$visitor_prior_form[j], 3, 9), "L")
          }
          
          if(adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(substr(adapted_df$visitor_prior_form[j], 3, 9), "L")
          }
        }
      }
}





if(adapted_df$home_team_name[j] == unique(regular_df$visitor_team_name)[i]){
  
      if(is.na(adapted_df$home_prior_form[j])){
          if(adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
            if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            
            adapted_df$visitor_prior_form[j+1] <- "W"
            }
            else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- "W"

            }
          }
        if(adapted_df$loser[j]  == unique(regular_df$visitor_team_name)[i]){
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            
            adapted_df$visitor_prior_form[j+1] <- "L"
            }
            else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- "L"

            }
        }
      }
      else if(nchar(adapted_df$home_prior_form[j]) < 9){
        
        if(adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
          
          adapted_df$visitor_prior_form[j+1] <- paste(adapted_df$home_prior_form[j], "W")
       
          }
          else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(adapted_df$home_prior_form[j], "W")
          }
        }
        else if(adapted_df$loser[j] == unique(regular_df$visitor_team_name)[i]){
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
          
          adapted_df$visitor_prior_form[j+1] <- paste(adapted_df$home_prior_form[j], "L")
       
          }
          else if (adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(adapted_df$home_prior_form[j], "L")
          }
        }
        }
        
 else if (nchar(adapted_df$home_prior_form[j]) >= 9){
        if (adapted_df$winner[j] == unique(regular_df$visitor_team_name)[i]){
          
          if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$visitor_prior_form[j+1] <- paste(substr(adapted_df$home_prior_form[j], 3, 9), "W")
          }
          
          if(adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(substr(adapted_df$home_prior_form[j], 3, 9), "W")
          }
          
            
            }
        else if (adapted_df$loser[j] == unique(regular_df$visitor_team_name)[i]){
          
          
           if(adapted_df$visitor_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$visitor_prior_form[j+1] <- paste(substr(adapted_df$home_prior_form[j], 3, 9), "L")
          }
          
          if(adapted_df$home_team_name[j+1] == unique(regular_df$visitor_team_name)[i]){
            adapted_df$home_prior_form[j+1] <- paste(substr(adapted_df$home_prior_form[j], 3, 9), "L")
          }
        }
      }
    }

    
    regular_df <- regular_df |> 
      rbind(adapted_df[j,])
    
}
}
#Add condition: away next game vs. home next game and then add it to column
    

```


```{r}

final_df <- na.omit(regular_df)

head(final_df)
```


```{r}
nba_api$TEAM_NAME = str_replace_all(nba_api$TEAM_NAME, "LA Clippers", "Los Angeles Clippers")


home2023_24 <- nba_api |> 
  right_join(final_df, join_by(GAME_DATE == date_game, TEAM_NAME == home_team_name)) |> 
    rename(opposition = visitor_team_name) 


away2023_24 <- nba_api |> 
  right_join(final_df, join_by(GAME_DATE == date_game, TEAM_NAME == visitor_team_name)) |> 
  rename(opposition = home_team_name) |> 
  relocate(32, .before = 31)

names(home2023_24) == names(away2023_24)

combined <- rbind(home2023_24, away2023_24)
combined
```

```{r}
#Sample code to find monthly averages




combined |> 
  filter(format(GAME_DATE, "%m") == "03") |> 
  group_by(TEAM_NAME) 
```

```{r}
# Load necessary libraries
library(dplyr)
library(readr)

# Load the dataset
game_stats <- combined

# Inspect the dataset
head(game_stats)

```

```{r}

# Calculate Team Shooting Percentage
game_stats <- game_stats %>%
  mutate(Shooting_Percentage = FGM / FGA) %>%
  group_by(TEAM_NAME) %>%
  mutate(Avg_Shooting_Percentage = mean(Shooting_Percentage, na.rm = TRUE))

# Calculate Average OREB per Game
game_stats <- game_stats %>%
  group_by(TEAM_NAME) %>%
  mutate(Avg_OREB = mean(OREB, na.rm = TRUE))

# Opposition Team's Historic DREB (this would require a bit more complex logic to calculate historically for each game)
game_stats <- game_stats %>%
  group_by(MATCHUP) %>%
  mutate(Opponent_Avg_DREB = mean(DREB, na.rm = TRUE))

game_stats
write.csv(game_stats, file = "my_data.csv", row.names = FALSE)
```

```{r}
# Splitting the data into training and testing sets 
set.seed(123)
training_indices <- sample(seq_len(nrow(game_stats)), size = floor(0.8 * nrow(game_stats)))
training_data <- game_stats[training_indices, ]
testing_data <- game_stats[-training_indices, ]

# Build the model
model <- lm(OREB ~ Avg_Shooting_Percentage + Avg_OREB + Opponent_Avg_DREB, data = training_data)

# Summary of the model
summary(model)

# Predict and evaluate
predictions <- predict(model, newdata = testing_data)
mae <- mean(abs(predictions - testing_data$OREB))
print(paste("Mean Absolute Error:", mae))

```


```{r}
game_stats <- game_stats %>%
  mutate(
    # Shooting Efficiency: Points per Field Goal Attempt and Free Throw Attempt
    SE = PTS / (FGA + 0.44 * FTA), # The 0.44 factor adjusts for and-one's, technical foul shots, and three-shot fouls
    
    # Defensive Pressure: Combining Steals and Blocks
    DP = (STL + BLK) / MIN, # Normalized by minutes played
    
    # Home Advantage as a binary variable
    Home = ifelse(grepl("vs", MATCHUP), 1, 0)
  )

# Prepare for modeling: Remove any rows with NAs created during feature engineering
game_stats <- na.omit(game_stats)
game_stats$Pace = (game_stats$FGA + 0.44 * game_stats$FTA + game_stats$TOV + game_stats$OREB) / game_stats$MIN
# Estimate possessions based on available stats
game_stats$Possessions <- with(game_stats, 0.96 * (FGA + 0.44 * FTA - OREB + TOV))

# Calculate ORtg and DRtg
game_stats <- game_stats %>%
  mutate(ORtg = 100 * PTS / Possessions,
         DRtg = 100 * ifelse(Home == 1, visitor_pts, home_pts) / Possessions)

game_stats
```

```{r}
game_stats$HomeFormScore <- stringr::str_count(game_stats$home_prior_form, "W") - stringr::str_count(game_stats$home_prior_form, "L")
game_stats$VisitorFormScore <- stringr::str_count(game_stats$visitor_prior_form, "W") - stringr::str_count(game_stats$visitor_prior_form, "L")
game_stats$TS = game_stats$AST * game_stats$FG_PCT
#Team Synergy (TS): A metric to quantify the effectiveness of a team's collaboration, which might not be directly observable through traditional stats. It can be approximated by the interaction between assists and shooting percentage, assuming higher synergy leads to more efficient scoring opportunities.#
game_stats$FormDiff <- game_stats$HomeFormScore - game_stats$VisitorFormScore
game_stats <- game_stats %>%
  select(-game_start_time, -home_prior_form, -visitor_prior_form) %>%
  na.omit()
game_stats <- game_stats %>%
  mutate(Spread = ifelse(Home == 1, home_pts - visitor_pts, visitor_pts - home_pts),
         Total = home_pts + visitor_pts)
game_stats

```

```{r}
library(tidyverse)
library(caret)
library(lubridate)
library(randomForest)
library(neuralnet)
```

```{r}
# Assuming 'game_data' is your prepared DataFrame
glm_model <- glm(Spread ~ FG_PCT + FG3_PCT + FT_PCT + REB + AST + STL + BLK + TOV + PF + Home + ORtg + DRtg + FormDiff, 
                 family = gaussian(), data = game_stats)
summary(glm_model)
```

```{r}
library(randomForest)

rf_model <- randomForest(Spread ~ FG_PCT + FG3_PCT + FT_PCT + OREB + DREB + AST + STL + BLK + TOV + PF + Home + Pace + Possessions + ORtg + DRtg + FormDiff, 
                         data = game_stats, 
                         ntree = 500, 
                         importance = TRUE)
print(rf_model)
varImpPlot(rf_model)
```

```{r}
# Assuming 'rf_model' is your trained Random Forest model and 'game_data' is your dataset
predictions <- predict(rf_model, game_stats)

# Actual outcomes
actuals <- game_stats$Spread

# Calculate RSS (Residual Sum of Squares)
RSS <- sum((actuals - predictions)^2)

# Calculate SST (Total Sum of Squares)
SST <- sum((actuals - mean(actuals))^2)

# Calculate R-squared
R2 <- 1 - (RSS / SST)

# Print the R-squared value
print(paste("R-squared:", R2))

```


```{r}
set.seed(123)
model_spread_2 <- randomForest(Spread ~ ORtg + DRtg + Pace + DP + FormDiff, data = game_stats)
print(model_spread_2)
```

```{r}
library(gbm)

gbm_model <- gbm(Spread ~ FG_PCT + FG3_PCT + FT_PCT + OREB + DREB + REB + AST + STL + BLK + TOV + PF + Home + Pace + Possessions + ORtg + DRtg + TS + FormDiff, 
                 data = game_stats, 
                 distribution = "gaussian", 
                 n.trees = 1000, 
                 shrinkage = 0.01, 
                 interaction.depth = 3, 
                 cv.folds = 5)
summary(gbm_model)
```
The results from Model 3, which appears to be from a Gradient Boosting Machine (GBM) or a similar tree-based ensemble model like Random Forest, show the relative importance (rel.inf) of various predictors in determining the Spread variable in NBA games. Let's interpret the significance of these results:

Key Variables and Their Importance
ORtg (Offensive Rating) and DRtg (Defensive Rating) are the most influential variables, with relative importances close to 50 each. This indicates that the efficiency of a team in offense and defense plays a critical role in determining the game's spread. High ORtg suggests a team is good at scoring per possession, while low DRtg suggests it is good at preventing the opponent from scoring, both of which can lead to larger victory margins.

FG_PCT (Field Goal Percentage): Although significantly less important than ORtg and DRtg, FG_PCT still plays a role in determining the spread, albeit minor (rel.inf around 0.63). This suggests that while overall shooting efficiency impacts game outcomes, its effect is far less pronounced than the team's overall offensive and defensive efficiency.

TS (True Shooting Percentage) and Possessions: These variables have even smaller relative importances, indicating a minor contribution to the model's prediction of Spread. True Shooting Percentage, which considers field goals, 3-point field goals, and free throws, and Possessions, which could indicate the game's pace, contribute to understanding how efficiently and quickly teams score.

DREB (Defensive Rebounds), PF (Personal Fouls), REB (Total Rebounds), and Pace: These variables have very low relative importance scores, suggesting their contribution to predicting Spread is minimal in this model.

FT_PCT (Free Throw Percentage), FG3_PCT (Three-Point Field Goal Percentage), AST (Assists), STL (Steals), TOV (Turnovers), and BLK (Blocks): These statistics have the least influence on the model, with relative importance values close to or at zero for some, indicating a negligible impact on Spread in the context of this model.

OREB (Offensive Rebounds), Home (Home Advantage), and FormDiff (Form Difference): These variables have a relative importance of zero, suggesting they do not contribute to the model's ability to predict Spread at all in this analysis.

Interpretation and Insights
The overwhelming importance of Offensive and Defensive Ratings underscores the idea that a team's efficiency, rather than raw statistical outputs like rebounds or assists, is what most significantly impacts game margins.
The minimal or zero importance of variables like Home Advantage and Form Difference in this model is intriguing, as conventional wisdom often suggests these factors matter. Their lack of impact here could be due to the overwhelming effect of ORtg and DRtg overshadowing these variables or could indicate that when it comes to Spread, the efficiency and performance metrics weigh much heavier.
The presence of zero-importance variables suggests either these factors truly have no predictive power for Spread in the context of other included variables, or the model may benefit from further tuning and possibly incorporating interaction terms or non-linear transformations to capture their effects better.
Conclusion
This model highlights the paramount importance of a team's efficiency on both ends of the court in determining the spread of NBA games. It suggests that for predictive modeling purposes, focusing on ORtg and DRtg provides the most significant insights into game outcomes, with other traditional box score metrics playing secondary roles. This analysis can guide more focused data collection and feature engineering efforts in future modeling work to improve predictive accuracy and efficiency.


```{r}
# Assuming you have a function to calculate MAE
calculate_mae <- function(predictions, actuals) {
  mean(abs(predictions - actuals))
}

# Example evaluation for the GLM model
predictions_glm <- predict(glm_model, newdata = game_stats)
mae_glm <- calculate_mae(predictions_glm, game_stats$Spread)
print(paste("GLM MAE:", mae_glm))

# Repeat for RF and GBM models and compare
predictions_rf <- predict(rf_model, newdata = game_stats)
mae_rf <- calculate_mae(predictions_rf, game_stats$Spread)
print(paste("RF MAE:", mae_rf))

predictions_gbm <- predict(gbm_model, newdata = game_stats)
mae_gbm <- calculate_mae(predictions_gbm, game_stats$Spread)
print(paste("GBM MAE:", mae_gbm))
```

The results show the Mean Absolute Error (MAE) for three different models - Generalized Linear Model (GLM), Random Forest (RF), and Gradient Boosting Machine (GBM) - applied to predict the NBA game spreads. The MAE metric measures the average magnitude of the errors in a set of predictions, without considering their direction. Lower MAE values indicate better model performance, as they suggest smaller discrepancies between the predicted and actual values.

Model Evaluation Summary:
GLM MAE: 0.5000 - The GLM has the lowest MAE among the three models, indicating that it has the best predictive accuracy for the game spreads on the given dataset. This suggests that the linear relationships captured by the GLM between the predictors and the Spread are significant and closely model the actual outcomes.

RF MAE: 0.8178 - The Random Forest model, despite being a powerful machine learning algorithm capable of capturing non-linearities and interactions between features, has the highest MAE. This could suggest that the model might be overfitting to the training data or that the complexity introduced by the Random Forest does not necessarily capture the underlying patterns more effectively than simpler models in this specific case.

GBM MAE: 0.6594 - The GBM model's performance lies between the GLM and RF, with its MAE being higher than the GLM but lower than the RF. While GBM is also capable of modeling complex relationships and interactions, its performance here indicates it does not outperform the simpler GLM approach for this particular task.

Insights and Implications:
Simplicity vs. Complexity: The results highlight an important aspect of predictive modeling - more complex models like RF and GBM are not always superior to simpler models like GLM, especially when the underlying relationships might be more linear or when the dataset size and feature space do not support complex pattern recognition without overfitting.

Model Selection: In practical applications, model selection should consider both performance metrics and the model's complexity. The GLM's superior performance suggests that for predicting NBA game spreads, a simpler, interpretable model might be more effective and efficient.

Further Investigation: The discrepancy in performance between the models warrants further investigation. For RF and GBM, exploring parameter tuning, feature selection, and addressing any potential overfitting could be ways to improve performance. Additionally, evaluating the models on a separate test set, if not already done, would provide more insight into their generalizability.

Domain Knowledge Integration: Integrating domain knowledge could further refine the models. For instance, considering external factors like player injuries, team fatigue, or recent team changes that are not captured by the model could enhance predictive accuracy.

The evaluation underscores the importance of exploring different modeling approaches and rigorously validating their performance to identify the most suitable model for a given prediction task.


```{r}
set.seed(123)
advanced_rf_model <- randomForest(Spread ~ ORtg + DRtg + Pace + DP + FormDiff + TS, data = game_stats, ntree = 500, mtry = 4, importance = TRUE)
print(advanced_rf_model)

# Predict on the training data
predictions <- predict(advanced_rf_model, game_stats)

# Calculate R-squared
actuals <- game_stats$Spread
SSE <- sum((actuals - predictions)^2)
SST <- sum((actuals - mean(actuals))^2)
R2 <- 1 - SSE/SST

print(paste("R-squared:", R2))

predictions_rf <- predict(advanced_rf_model, newdata = game_stats)
mae_rf <- calculate_mae(predictions_rf, game_stats$Spread)
print(paste("Advanced RF MAE:", mae_rf))
```

The reported Mean Absolute Error (MAE) for the "Advanced RF" (Random Forest) model is 0.3650. This metric represents the average absolute difference between the predicted values by the model and the actual values in the dataset for the NBA game spreads. A lower MAE indicates a better fit of the model to the data, meaning the predictions are closer to the actual outcomes.

Comparison with Previous Models
When comparing this result to the previously mentioned models:

GLM MAE: 0.5000
RF MAE: 0.8178
GBM MAE: 0.6594
Advanced RF MAE: 0.3650
The "Advanced RF" model shows the lowest MAE among all the models discussed, indicating it has the highest predictive accuracy for this particular task.

Interpretation
Model Performance: The "Advanced RF" model outperforms the simpler GLM, the basic RF, and the GBM models in terms of predictive accuracy for the Spread variable. This suggests that whatever advancements or optimizations were applied to the "Advanced RF" model (such as feature engineering, hyperparameter tuning, or incorporating additional relevant predictors) have significantly improved its ability to predict NBA game spreads accurately.

Predictive Accuracy: An MAE of 0.3650 signifies that, on average, the predictions made by the "Advanced RF" model are within approximately 0.365 points of the actual game spread. This level of accuracy is quite impressive in the context of sports predictions, where many unpredictable factors can influence game outcomes.

Implications for Strategy: The superior performance of the "Advanced RF" model could have practical implications for stakeholders interested in NBA game outcomes, such as sports analysts, bettors, or team strategists. The model's accuracy suggests it could be a reliable tool for forecasting game spreads and making informed decisions based on those predictions.

Conclusion
The "Advanced RF" model demonstrates a significant improvement in predicting the Spread variable compared to other models. Its success highlights the importance of iterative model refinement, including exploring advanced modeling techniques, feature selection, and hyperparameter optimization, to enhance predictive performance. Additionally, the results underscore the potential value of machine learning models in sports analytics, offering insights that can support decision-making processes in various contexts related to NBA games.















Mean of Squared Residuals (MSR): The MSR value is 2.557157, which is relatively low. This metric represents the average of the squared differences between the observed actual outcomes and the predictions made by the model. A lower MSR indicates that the model's predictions are, on average, very close to the actual game spreads, suggesting high accuracy in the predictions.

Percentage of Variance Explained: The model explains 98.96% of the variance in the Spread, which is exceptionally high. This metric reflects the model's ability to capture the underlying patterns and relationships in the data that contribute to the outcome variable. A value this high suggests that the model is highly effective at predicting game spreads based on the selected predictors.

Interpretation
Predictive Power: The model's high percentage of variance explained, coupled with the low mean of squared residuals, indicates that it is extremely effective at predicting the spread of NBA games. This suggests that the combination of variables used, including both individual performance metrics like ORtg and DRtg, as well as team dynamics indicators like TS, provides a comprehensive set of predictors for understanding game outcomes in terms of spread.

Variable Selection: The choice to include variables such as ORtg, DRtg, and Pace aligns with conventional wisdom about factors that influence game outcomes. The inclusion of DP and FormDiff captures aspects of defensive intensity and recent performance trends, respectively, which are intuitively relevant to predicting spreads. TS as a measure of team synergy introduces a novel aspect into the predictive model, implying that how well a team plays together (beyond individual stats) is crucial for game outcomes.

Model Robustness: The configuration of the Random Forest, with a substantial number of trees and a thoughtful selection of variables at each split, likely contributes to its robustness and high explanatory power. The model benefits from Random Forest's inherent strengths, such as handling non-linear relationships and interactions between variables without explicit specification.

Conclusion
This Random Forest model demonstrates outstanding performance in predicting NBA game spreads, as evidenced by its near-perfect variance explanation and low mean squared residuals. The results suggest that the model, with its current configuration and variable selection, effectively captures the complexities and dynamics influencing NBA game outcomes.


